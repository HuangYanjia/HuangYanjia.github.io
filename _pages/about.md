---
layout: about
title: about
permalink: /
subtitle: >
  <a href="https://engineering.tamu.edu/entc/index.html" target="_blank">Texas A&amp;M University</a> &nbsp;·&nbsp;
  Graduate Research Assistant &nbsp;·&nbsp;
  Robotics &amp; Embodied AI

profile:
  align: right
  image: image.png
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>Mechanical Engineering</p>
    <p>Texas A&amp;M University</p>
    <p>College Station, TX 77840, USA</p>
    <p><a href="mailto:yanjia_0812@tamu.edu">yanjia_0812@tamu.edu</a></p>

news: false  # includes a list of news items 
<!-- latest_posts: false  # includes a list of the newest posts -->
selected_papers: true # includes a list of papers marked as "selected={true}" 
social: false  # includes social icons at the bottom of the page
announcements:
  enabled: false
  scrollable: true
  limit: 5

latest_posts:
  enabled: false
  scrollable: true
  limit: 3
---


I am **Yanjia Huang**, an M.S. student in Mechanical Engineering at **Texas A&M University**, where I am a member of the <a href="https://taco-group.github.io/" target="_blank">TACO Group</a> led by Prof. <a href="https://vztu.github.io/" target="_blank">Zhengzhong Tu</a>.
My research explores how *vision-language models*, *diffusion policy learning* can be woven together to produce robust, long-horizon plans for **embodied agents**—from indoor navigation to dexterous manipulation.

Prior to my graduate studies at Texas A&M, I completed a dual-degree program in Mechanical Engineering at the <a href="http://www.sbcen.usst.edu.cn/" target="_blank">Sino-British College (SBC), USST</a> and <a href="https://www.ljmu.ac.uk/" target="_blank">Liverpool John Moores University (LJMU)</a>, where I also pursued a minor in Physics. My passion for research was ignited during my time as a research assistant with Prof. <a href="http://yanweifu.github.io/" target="_blank">Yanwei Fu</a> at <a href="https://www.fudan.edu.cn/en/" target="_blank">Fudan University</a> and at NYU's <a href="https://ai4ce.github.io/" target="_blank">AI4CE Lab</a> (advised by Prof. <a href="https://engineering.nyu.edu/faculty/chen-feng" target="_blank">Chen Feng</a>) and <a href="https://yifang.org/group.html" target="_blank">Multimedia and Visual Computing Lab (MMVC)</a> (advised by Prof. <a href="https://nyuad.nyu.edu/en/academics/divisions/engineering/faculty/yi-fang.html" target="_blank">Yi Fang</a>). This passion was further solidified during my internship at <a href="https://www.huawei.com/en/corporate-information/research-development" target="_blank">Huawei's Noah's Ark Lab</a>, mentored by <a href="https://xuhangcn.github.io/" target="_blank">Hang Xu</a>.

Get full <a href="/assets/pdf/CV_Yanjia_Huang.pdf" target="_blank">curriculum vitae</a> here.

Have a collaboration idea or just want to chat? Shoot me an email—coffee’s on me.


<!-- Outside the lab you’ll find me at a piano, on a hiking trail, or cycling. -->
> *“Robots shouldn’t just imitate; they should **imagine**, **reason**, and **plan**.”*

<!-- **Recent highlights**

* **VISTA** — Developed VISTA, a novel scheduling framework that leverages a diffusion model for "visual imagination," enabling embodied agents to proactively plan and recover from low-confidence states.
* **PANDORA** — Designed PANDORA, a diffusion-based control policy that generates fine-grained, expressive motor commands for the complex task of robotic piano playing. (IROS 2025, under review)
* Applied **Monte-Carlo Tree Diffusion (MCTD)** to enhance planning in Vision-Language Agents (VLAs), enabling efficient search over long-horizon, goal-conditioned motions for zero-shot object manipulation.   -->





